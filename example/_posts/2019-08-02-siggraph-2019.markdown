---
layout: post
title:  "SIGGRAPH 2019"
---
[SIGGRAPH 2019](https://s2019.siggraph.org/) was a fantastic event, full of inspiring people and astonishing technology. The presence of Unity and Epic Games was large this time. And the work of Unity's research scientist [Eric Heitz](https://eheitzresearch.wordpress.com/) was cited everywhere.

This is an informal report of the talks that I attended.

### Real-time rendering in the industry

**Advances in Real-Time Rendering in Games: Part I & II:** This was a day-long course organized by Unity. It featured presentations by major players of the gaming industry, like Unity itself, Rockstar (Red Dead Redemption 2), EA/Frostbite, and Sony Santa Monica (God of War). Slides are slowly becoming available [here](http://advances.realtimerendering.com/s2019/index.htm). Slides of previous years are available [here](http://advances.realtimerendering.com/). These weren't just high-level descriptions, but deep-dives with code snippets, equations and diagrams. What follows are my impressions and key takeaways. I confess that I didn't understand much of the content, so I won't try to reproduce or summarize it here; the [abstracts](http://advances.realtimerendering.com/s2019/index.htm) here are a much better way to get a sense of the contents of each talk.

- **A Journey Through Implementing Multiscattering BRDFs and Area Lights (Ubisoft):** I learned that SIGGRAPH has hosted a series of courses on *Physically-based shading* [over the years](https://blog.selfshadow.com/publications/s2017-shading-course/), not real-time necessarily.

- **Leveraging Real-Time Ray Tracing to build a Hybrid Game Engine (Unity):** By *hybrid* one means *rasterization + ray tracing*, and one of the main points the presenter tried to make was that ray tracing alone is not always the best; he even has a rather impassioned blog post [here](https://auzaiffe.wordpress.com/2019/03/26/a-hybrid-rendering-pipeline-for-realtime-rendering-when-is-raytracing-worth-it/) where he tries to deflate the current ray tracing craze. Unity's [High Definition Render Pipeline](https://github.com/Unity-Technologies/ScriptableRenderPipeline), or HDRP, is a C# API that allows users to build their own rendering pipelines; the [Reality vs Illusion demo](https://www.youtube.com/watch?v=AG7DDXwYpD0) was produced with it, it intersperses real-time ray-traced animation with real footage, and it is absolutely gorgeous (at a later talk, a Unity engineer revealed that the demo has major flaws, especially when it comes to accurate reflections, despite its evident beauty); that's Charles Bukowski there. Physically-based lighting is at the core of the HDRP and allows for 5 kinds of "effects": Ambient occlusion, indirect diffuse, indirect specular for opaque object reflections, recursive tracing for transparent object reflections, and stochastic area shadows. For *sampling-based integration*, which is at the core of path tracing, he referred us to the work of [Eric Heitz](https://eheitzresearch.wordpress.com/research/). The presenter walked us through each and every step of the render graph. There's a video of the exact same presentation, but at the Digital Dragons conference [here](https://www.youtube.com/watch?v=wbuvrAdNtmQ) ([slides](https://auzaiffe.files.wordpress.com/2019/05/digital-dragons-leveraging-ray-tracing-hardware-acceleration-in-unity.pdf)). **Keywords:** Ray binning, ray budget, multi-scattered BRDF, area lights and linearly transformed cosines ([LTC](https://eheitzresearch.wordpress.com/415-2/)).

- A separate talk titled *Leveraging Ray Tracing Hardware Acceleration in Unity* delved into the details of the design of Unity's HDRP. Slides aren't available yet, though.

- **Strand-based Hair Rendering in Frostbite (EA):** [Frostbite](https://www.ea.com/frostbite) is EA's game engine. Rasterization only. [Deep Opacity Maps](http://www.cemyuksel.com/research/deepopacity/) is the state of the art technique for rendering hair in real time and it solves 3 challenges: Single hair scattering, azimuthal scattering, multiple scattering (hair strands); I have no more info on each. EA promised to release a series of technical blog posts over the coming months starting [here](https://www.ea.com/frostbite/news/frostbite-hair-rendering-and-simulation). **Keywords:** Deep opacity maps, hair cards, triangle strips.


- **Interactive Wind and Vegetation in 'God of War' (Sony Santa Monica):** The presenter emphasized the iterative nature of the development of most complex systems, with GoW's wind system being a prime example. The effects of wind (on vegetation as well as on the character's hair, beard and clothes) and those of the interaction of the character with its environment are subtle, but create an immersive and believable experience for the player; emphasis on the word *believable*, rather than *realistic*, as striving for realism in such complex systems is bound to reach a point of diminishing returns with the current state of technology. An interesting point was the concept of *debug visualization*: Little tools that the developer writes to visualize the behavior and effects of the system; slides 33 and 34 [here](http://bit.ly/windsimGOW) contain videos of examples of debug visualization. **Keywords:** Wind vectors, wind motors, wind receivers (audio, cloth, particles, and meshes), wind mask, logarithmic binning, weather flow maps and flow flips, billboard clouds, cards and clusters, Beaufort scale, particle ribbon trails.

- **Multi-resolution Ocean Rendering in Crest Ocean System (Electric Square):** Ocean simulation for Unity. This was a promising talk that disappointed: Most other presenters used beautiful or interesting interactive visualizations or videos. This person just talked and showed a few images. Pirate Cove scene [video](https://www.youtube.com/watch?v=3i6VpdKw2Q0). [Repo](https://github.com/crest-ocean/crest).

- **Creating the Atmospheric World of Red Dead Redemption 2:** A Complete and Integrated Solution (Rockstar): This was my favorite talk of all the conference. The focus was on volumetric rendering of fog, clouds, rain clouds, lightning, and even rainbows (although rainbows, they said, are not physically-based) for vast natural environments. Voxelization is used to render at the near distance and ray marching at the far distance. The slides contain footnotes, check them out. **Keywords:** Ray marching, raymarch reconstruction, ray length, voxelization, volumetric scattering, transmittance, material extinction parameter, extinction volumes, Perlin and Worley noise, ambient light, checkerboard min/max depth downsampling.

**Open Problems in Real-Time Rendering: Part I & II:** This was a day-long series of presentations where prominent figures (Natalya Tatarchuk, Matt Pharr) and experts of the field talked about some of the problems that remain open in real-time rendering. Each year the focus is different and this year it was *physically-based lighting with real-time constraints*. Slides will appear [here](https://openproblems.realtimerendering.com/) eventually. What follows are the talks that I attended.

- 2018 saw the arrival of the first ray-traced AAA games: Control and Shadow of the Tomb Raider, to name a few. However, none of them are fully ray-traced: [Q2VKPT](http://brechpunkt.de/q2vkpt/) (Q is for *Quake*, VK is for *Vulkan*, PT is for *Path Tracing*) is *"the first playable game that is entirely raytraced and efficiently simulates fully dynamic lighting in real-time, with the same modern techniques as used in the movie industry... Q2VKPT is the first project to implement an efficient unified solution for all types of light transport: direct, scattered, and reflected light"*. The [code is open source](https://github.com/cschied/q2vkpt/).

- **Game Engine Design (Tatarchuk, Unity):** Games have 10x more geometry than before. Shader code is getting huge. [Shader/material permutation](https://medium.com/@lordned/unreal-engine-4-rendering-part-5-shader-permutations-2b975e503dd4) compilation explosion, exacerbated by ray tracing. Artists are forced to limit the number of lights that participate in light transport. Texture LOD management and BVH management need to improve. **Keywords:** Ubershaders, Lambert lobes, shader kernels, artist graphs.

- **Path Tracing for Future Games (Pharr, NVIDIA):** The talk started off with an important clarification: Ray tracing and path tracing are not different names for the same thing. Path tracing is a "unified light transport algorithm based on random sampling (Monte Carlo integration)". Ray tracing is a "geometric algorithm that computes ray-based visibility". Then he went on to explain path tracing in detail and give examples of notable work out there ([ray-traced Minecraft](https://www.gamecrate.com/how-to-set-up-ray-tracing-minecraft/22982), [ray-traced reflections in EA's Battlefield V](https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s91023-it-just-works-ray-traced-reflections-in-battlefield-v.pdf)). The open problems he discussed were: Ray coherence/incoherence; better data structures for visibility; denoising; BSDF and microfacets; sampling well under sample reprojection; does sorting rays really improve performance?; is there a ray tracing equivalent to conservative rasterization? He is especially interested in the last one. He praised 2 SIGGRAPH '19 papers: *Distributing Monte Carlo Errors as a Blue Noise in Screen Space by Permuting Pixel Seeds Between Frames* ([Heitz](https://eheitzresearch.wordpress.com/), [paper](https://eheitzresearch.wordpress.com/772-2/)) and *Volume Path Guiding Based on Zero-Variance Random Walk Theory* (Herholz, described in this doc elsewhere). **Keywords:** HDRi environment lighting Monte Carlo estimator, importance sampling estimator, importance sampling diffuse direct lighting, direct lighting estimator, environment map luminance, path guiding, point-sample distributions, progressive sample sequences, ray frusta, conservative occluders.

- **Scaling Light Complexity (Karis, Kelly, Epic Games):** There is a limit to the number of direct dynamic lights that can be used; dynamic lighting can only scale when computation becomes sublinear in the number of lights. Baked light maps are being used instead (*Precomputed Global Illumination*, Frostbite, [slides](https://media.contentapi.ea.com/content/dam/eacom/frostbite/files/gdc2018-precomputedgiobalilluminationinfrostbite.pdf)). A 2nd problem he discussed was that of maintaining more than 25 shadow methods in UE4; a single one can't be used because most modern methods are supported only by the latest hardware. **Keywords:** HL2 basis, directional basis, spherical harmonics, froxels, proxy light, area lights, LOD with shadow proxies, shadow caching, dynamic lights, baked light maps.

### Path tracing in production

- This was a day-long course delivered in 2 parts: [Modern Path Tracing](http://delivery.acm.org/10.1145/3330000/3328079/a19-fascione.pdf?ip=199.188.193.122&id=3328079&acc=OPENTOC&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E383ADA7593775D6F&__acm__=1564767217_9a00bcaab2360410617b826fca79e32a) and [Making Movies](http://delivery.acm.org/10.1145/3330000/3328085/a20-jakob.pdf?ip=199.188.193.122&id=3328085&acc=OPENTOC&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E383ADA7593775D6F&__acm__=1564767637_67aa8210bbee5ae27b0567cd5319e890). The course dove deep into the theory of path tracing and how it is used to create the shading effects that we see in movies like *Alita: Battle Angel*, *Spider-Man Far From Home*, and *Lego Movie*. I won't summarize any of it here because my understanding is limited and because those 2 linked documents explain everything in generous detail. **Keywords:** Path sampling framework, stereo techniques, next event estimation, [Manuka](https://www.wetafx.co.nz/research-and-tech/technology/manuka/) micropolygon renderer, light hierarchy, acceleration structures for next event estimation, fitness and BSDF biasing, equiangular sampling, transmittance sampling, biased ray marching, null scattering.

### GPU architecture

- **Mesh Shading: Towards Greater Efficiency Of Geometry Processing (NVIDIA)**: NVIDIA presented Mesh Shading as the next major step in the evolution of the GPU. The presentation starts with a history of this evolution: Fixed function stages, followed by programmable vertex shaders, followed by compute shaders, and now mesh shaders. 2 new shaders that precede rasterization replace the old shaders: The task shader and the mesh shader. Turing GPUs only. The redesign of the rendering pipeline comes with a redefined programming model that enables greater efficiency and control in geometry processing and that opens up many new applications and offloads much of the burden of LOD management. The Vulkan & OpenGL CAD Mesh Shader Sample [repo](https://github.com/nvpro-samples/gl_vk_meshlet_cadscene) demonstrates the new programming model. [NVIDIA's Asteroids demo](https://devblogs.nvidia.com/using-turing-mesh-shaders-nvidia-asteroids-demo/) is a great example of LOD management taking place in task shaders, as opposed to in the CPU. [Adaptive GPU Tessellation](http://onrendering.com/data/papers/isubd/isubd.pdf) was demonstrated with the generation of terrain whose mesh was handled entirely by the GPU ([repo](https://github.com/jdupuy/opengl-framework/tree/master/demo-isubd-terrain)). **Keywords:** adaptive GPU tessellation, meshlets, task and mesh shaders.

### Academic papers

Research papers across [32 different categories](https://s2019.siggraph.org/conference/programs-events/technical-papers/) were presented. The [Technical Papers Fast Forward session](https://www.youtube.com/watch?v=iDUNc5YRtzk) presents all of them briefly. I attended those of the **Advanced Volume Rendering** and **Meshing** categories. I wish I had attended the **Light Science** (Optimal Multiple Importance Sampling, Kondapaneni, [paper](https://graphics.cg.uni-saarland.de/papers/konda-2019-siggraph-optimal-mis.pdf)) and **High Performance Rendering** categories.

#### Advanced Volume Rendering

- **Volume Path Guiding Based on Zero-Variance Random Walk Theory (Herholz):** This was a widely-cited paper. It was mentioned in a couple other talks, including the one by Matt Pharr on [Open Problems in Real-Time Rendering](https://openproblems.realtimerendering.com/). Guided path tracing performs well in challenging scenes with poor lighting and participating media (dust in the air, in the example), with fewer speckles ("fireflies") in the end result. The von Mises-Fisher probability distribution is at the core of the algorithm, and Matt Pharr confessed he was delighted by it. The source code of the implementation by the author will be available soon if requested at sebastian.herholz@gmail.com. **Keywords:** Guided and unguided path tracing, volumetric Monte-Carlo, kd-tree spatial cache, von Mises-Fisher, guided russian roulette and splitting.

- **A Null-Scattering Path Integral Formulation of Light Transport (Miller, [paper](https://cs.dartmouth.edu/~wjarosz/publications/miller19null.html)):** The slides of this talk contain a great introduction to path tracing through volumetric media (they are not public yet). They also include a beautiful render of light passing through a bunny-shaped smoke cloud. I have no more info. **Keywords:** Multiple importance sampling (MIS), scattering, transmittance, null-scattering path integrals, diffuse manifolds, color majorant, next event estimation.

- **Fractional Gaussian Fields for Modeling and Rendering of Spatially-Correlated Media (Guo, [paper](https://sites.cs.ucsb.edu/~lingqi/publications/paper_fgf.pdf)):** No info. **Keywords:** Random fields, fractional integral operator, fractional Laplacian, autocovariance function, pink noise, extinction field, transport kernel, [Open Shading Language](https://github.com/imageworks/OpenShadingLanguage).

- **Photon Surfaces for Robust, Unbiased Volumetric Density Estimation (Deng, [paper](https://cs.dartmouth.edu/~wjarosz/publications/deng19photon.pdf)):** No info. **Keywords:** Photon mapping, participating media, 1D and 3D blur, photon plane.

#### Meshing

- I noticed that nobody talks about the applications of meshing research and computational geometry in games and film; it is probably at the core of every game engine, though. The people who do talk about that are the folks in the 3D printing industry (Carbon Inc. gave a talk titled *Computational Geometry and Software at Carbon*) and those interested in simulation of physical phenomena.

- **Parametrization Quantization With Free Boundaries for Trimmed Quad Meshing (Lyon, [paper](https://www.graphics.rwth-aachen.de/media/papers/300/LyonCampenBommesKobbelt_Siggraph2019_TrimmedQuadMeshing.pdf)):** This technique produces smoother and nicer quad meshes. They said it's suitable for building *roof meshes* in *architectural visualization*. **Keywords:** Quad meshes, singularities, quantized global parametrization, motorcycle graphs, patches, Dijkstra, T-junctions, integer grid maps. Image source: Paper.

- **TriWild: Robust Triangulation with Curve Constraints (Hu, [paper](https://www.cs.toronto.edu/~jacobson/images/triwild-robust-triangulation-with-curve-constraints-siggraph-2019-compressed-hu-et-al.pdf), [repo](https://github.com/wildmeshing/TriWild/tree/master)) and TetWild:** Tetrahedral Meshing in the Wild (Hu, [paper](https://cs.nyu.edu/~yixinhu/tetwild.pdf), [repo](https://github.com/Yixin-Hu/TetWild)): TriWild triangulates 2D images described by curved contours, achieving correct color diffusion and smoother boundaries. TetWild tetrahedralizes the interior of a 3D shape. **Keywords:** Triangulation, tetrahedralization, 2D, segment soups, linear and curved mesh generation, vertex smoothing, edge collapsing, envelope size. Image sources: Papers.

- **Finding Hexahedrizations for Small Quadrangulations of the Sphere (Verhetsel, [paper](https://arxiv.org/pdf/1904.11229.pdf)):** Hexahedrization is the subdivision of a volume into several hexahedra. I have no idea what it is used for, but it looks very cool. They have a [website](https://www.hextreme.eu/). Keywords: Hexahedrization, quad sections, tet meshes, quadrangulation. Image source: Paper.

- **Harmonic Triangulations (Alexa, [paper](http://cybertron.cg.tu-berlin.de/~alexa/hts.pdf)):** The interesting thing about this presentation was the way that the author explained and related with each other classical concepts of Computational Geometry: Delaunay triangulations, Voronoi diagrams and convex hulls. **Keywords:** Dirichlet energy, piecewise linear surfaces, Rippa's theorem, bistellar flips, harmonic flips, pedal triangles and tetrahedra, harmonic flipping vs sliver exudation. Image source: Paper.

- **Navigating Intrinsic Triangulations (Sharp, Crane, [paper](https://www.cs.cmu.edu/~kmcrane/Projects/NavigatingIntrinsicTriangulations/paper.pdf)):** Correct meshing is important because algorithms may fail on them otherwise. This paper introduces a data structure called signpost that allows a large set of existing mesh processing algorithms to succeed on poor-quality meshes. A very interesting thing about the paper is that the resulting triangles of the triangulation are not necessarily planar (intrinsic triangulation). This paper and others by CMU are the work of a group called the [Geometry Collective](http://geometry.cs.cmu.edu/). Keenan Crane has a great [free book](https://www.cs.cmu.edu/~kmcrane/Projects/DDG/paper.pdf) on Discrete Differential Geometry. **Keywords:** Signpost data structure, triangle cotangent weights, geodesic paths, edge flips, Delaunay triangulation, intrinsic Delaunay refinement and vertex insertion, Steiner trees, adaptive mesh refinement. Image source: Paper.

### Other

- A number of [denoisers](https://s2019.siggraph.org/press/press-releases/novel-denoising-method-generates-sharper-photorealistic-images-faster/) were on display on the show floor plus research presented in the conference.

- [Are we done with ray tracing?](https://sites.google.com/view/arewedonewithraytracing) (Conclusion, not quite yet.) The history of the evolution of ray tracing techniques, performance evaluations, challenges and open problems. By NVIDIA, EA, and even Facebook.

- [Geometric Computing with Python](https://drive.google.com/open?id=1Qzs7nykg5oHbrZY5uUkKTmnSnNhMfbpi): A course that teaches many advanced geometry processing and visualization methods using Python. Online Jupyter notebooks can be found here.

- [Immersive Math](http://immersivemath.com/ila/index.html): An online linear algebra book with fully interactive figures, by T. Akenine-Möller, author of [Real-Time Rendering](https://www.crcpress.com/Real-Time-Rendering-Fourth-Edition/Akenine-Moller-Haines-Hoffman/p/book/9781138627000).

- All of the [ray tracing talks, courses and events](http://www.realtimerendering.com/raytracing/roundup.html).

- All of the [courses](https://www.siggraph.org/wp-content/uploads/2019/07/OpenAcess-for-SIGGRAPH-2019-Courses.html).

- An alternative [collection of links](https://blog.selfshadow.com/2019/07/30/siggraph-2019-links/).

- [Tips and Tricks: Ray Tracing Best Practices](https://devblogs.nvidia.com/rtx-best-practices/) for NVIDIA RTX.

- NVIDIA presented the book [Ray Tracing Gems](http://www.realtimerendering.com/raytracinggems/). I started to read it and it's great. Part 5 is all about denoising.